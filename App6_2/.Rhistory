length(indext)
dim(Ad)
n = dim(A)[1]
K2 = K1
##############################################
##### Model fitting
system.time({m1 = model1(A,Ad,indext,K1,X,n)})
beta <- do.call(rbind, m1)
beta = t(beta)
yseq = seq(1,max(df$case_count)+10,0.1)
Ay <- bernsteinPoly(yseq, degree = 20, intercept = FALSE,Boundary.knots = c(1,max(df$case_count)+10))
Ay <- sweep(Ay,2,cmx)
Ayd <- deriv(Ay)
q = ncol(Ay)
Sigma <- matrix(1,q,q)                             # Duplicate matrix
Sigma[upper.tri(Sigma)] <- 0          # Change lower triangular part
qi = vector()
qs = vector()
qm = vector()
ey = vector()
Ay = Ay%*%Sigma
Ayd = Ayd%*%Sigma
length(qm)
Quantil = matrix(0,dim(A)[1],9)
gamma2 = apply(beta,1,gamma_f,index = indext)
h1 = apply(Ay%*%gamma2[1:ncol(Ay),],1,mean)
h1l = apply(Ayd%*%gamma2[1:ncol(Ay),],1,mean)
for(j in 1:dim(X)[1]){
#print(j)
#j = sample(1:dim(A)[1],1)
#A <- sweep(A,2,cmx)
#h1 = Ay%*%gamma[1:ncol(Ay)]
h2 = mean(c(X[j,]%*%gamma2[(ncol(Ay)+1):(ncol(A)),]))
#Fy = pnorm(c(Apred%*%gamma[1:ncol(Apred)]) + gamma[c(length(gamma))] + c(Bx2[j,]%*%gamma[(ncol(Apred) + 1):(length(gamma) - 1)]))
Fy = pnorm(h1 + h2)
fy = dnorm(h1 + h2)*h1l
ey[j] = sum(fy*diff(yseq)[1]*yseq)
#Fy = pnorm(c(Apred%*%gamma[1:ncol(Apred)]) + c(X[j,]*gamma[c(length(gamma))]))
# usar 0.025,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.975
Quantil[j,1] = (yseq[Fy > 0.025])[1]
Quantil[j,2] = (yseq[Fy > 0.05])[1]
Quantil[j,3] = (yseq[Fy > 0.1])[1]
Quantil[j,4] =(yseq[Fy > 0.25])[1]
Quantil[j,5] = (yseq[Fy > 0.5])[1]
Quantil[j,6] =  (yseq[Fy > 0.75])[1]
Quantil[j,7] = (yseq[Fy > 0.9])[1]
Quantil[j,8] =  (yseq[Fy > 0.95])[1]
Quantil[j,9] = (yseq[Fy > 0.975])[1]
}
ey
#datapred_model1 = as.data.frame(cbind(df,qm,qi,qs,ey))
datapred_model1 = as.data.frame(cbind(df,Quantil,ey))
datapred = datapred_model1
head(datapred)
cr = 1 - sum(datapred$case_count > datapred$`9` | datapred$case_count < datapred$`1`)/(nrow(datapred))
cr
#df$predict2 = datapred$qm
mean(abs(ey - df$case_count))
quantiles = c(0.025,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.975)
pred = (Quantil)
indices = order(pred[,5])
pred = t(pred[order(pred[,5]),])
pred = c(pred)
#
i <- 1:nrow(df)
nd <- expand.grid(quantile = factor(quantiles), i = i)
#
df_sorted = df[indices,]
nd <- cbind(nd, df_sorted[nd$i,,drop = FALSE])
nd$predict <- pred
newdat <- nd
head(newdat)
#newdat$Subject <- factor(paste("Subject =", newdat$Subject))
#data$Subject <- factor(paste("Subject =", data$Subject))
## Usar esse gráfico
ggplot(newdat, aes(x = seq_along(predict), y = predict, color = quantile)) +
geom_line(size = 1) +
geom_point(aes(x = seq_along(predict), y = case_count), data = newdat, color = "black", alpha = 0.3,
size = 0.75) +
#geom_line(aes(x = Days, y = Reaction), data = data, color = "black", alpha = 0.3) +
facet_wrap(~ month, nrow = 3) +
ylab("Average reaction time (ms)") +
labs(colour = "Estimated conditional quantiles") +
colorspace::scale_color_discrete_diverging("Blue-Red2") +
theme(panel.grid.major = element_line(colour = "lightgrey", size = 0.3,
linetype = "dotted"),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
strip.background = element_rect(colour = "black", fill = "white"),
axis.line = element_line(colour = "black"),
axis.title = element_text(size = rel(0.9)),
legend.title = element_text(size = rel(0.9)),
legend.position = "bottom",
legend.key = element_rect(fill = "transparent", colour = "transparent")) +
guides(colour = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1))
df_backup
df_teste = df_backup[floor(dim(df)[1] + 1):dim(df_backup)[1],]
ey = vector()
Xpred =  model.matrix(~ year + mes + dia + dia*Period2, data = df_teste)
Quantil = matrix(0,dim(Xpred)[1],9)
for(j in 1:dim(Xpred)[1]){
print(j)
#j = sample(1:dim(A)[1],1)
#A <- sweep(A,2,cmx)
#h1 = Ay%*%gamma[1:ncol(Ay)]
h2 = mean(c(Xpred[j,]%*%gamma2[(ncol(Ay)+1):(ncol(A)),]))
#Fy = pnorm(c(Apred%*%gamma[1:ncol(Apred)]) + gamma[c(length(gamma))] + c(Bx2[j,]%*%gamma[(ncol(Apred) + 1):(length(gamma) - 1)]))
Fy = pnorm(h1 + h2)
fy = dnorm(h1 + h2)*h1l
ey[j] = sum(fy*diff(yseq)[1]*yseq)
#Fy = pnorm(c(Apred%*%gamma[1:ncol(Apred)]) + c(X[j,]*gamma[c(length(gamma))]))
Quantil[j,1] = (yseq[Fy > 0.025])[1]
Quantil[j,2] = (yseq[Fy > 0.05])[1]
Quantil[j,3] = (yseq[Fy > 0.1])[1]
Quantil[j,4] =(yseq[Fy > 0.25])[1]
Quantil[j,5] = (yseq[Fy > 0.5])[1]
Quantil[j,6] =  (yseq[Fy > 0.75])[1]
Quantil[j,7] = (yseq[Fy > 0.9])[1]
Quantil[j,8] =  (yseq[Fy > 0.95])[1]
Quantil[j,9] = (yseq[Fy > 0.975])[1]
}
datapred = as.data.frame(cbind(df_teste,Quantil,ey))
#datapred = datapred_model1
head(datapred)
#cr = 1 - sum(datapred$case_count > datapred$qs | datapred$case_count < datapred$qi)/(nrow(datapred))
#cr
#df$predict2 = datapred$qm
mean(abs(ey - df_teste$case_count))
quantiles = c(0.025,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.975)
pred = (Quantil)
indices = order(pred[,5])
pred = t(pred[order(pred[,5]),])
pred = c(pred)
#
i <- 1:nrow(df_teste)
nd <- expand.grid(quantile = factor(quantiles), i = i)
#
df_sorted = df_teste[indices,]
nd <- cbind(nd, df_sorted[nd$i,,drop = FALSE])
nd$predict <- pred
newdat <- nd
head(newdat)
#newdat$Subject <- factor(paste("Subject =", newdat$Subject))
#data$Subject <- factor(paste("Subject =", data$Subject))
## Usar esse gráfico
ggplot(newdat, aes(x = seq_along(predict), y = predict, color = quantile)) +
geom_line(size = 1) +
geom_point(aes(x = seq_along(predict), y = case_count), data = newdat, color = "black", alpha = 0.3,
size = 0.75) +
#geom_line(aes(x = Days, y = Reaction), data = data, color = "black", alpha = 0.3) +
facet_wrap(~ month, nrow = 3) +
ylab("Average reaction time (ms)") +
labs(colour = "Estimated conditional quantiles") +
colorspace::scale_color_discrete_diverging("Blue-Red2") +
theme(panel.grid.major = element_line(colour = "lightgrey", size = 0.3,
linetype = "dotted"),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
strip.background = element_rect(colour = "black", fill = "white"),
axis.line = element_line(colour = "black"),
axis.title = element_text(size = rel(0.9)),
legend.title = element_text(size = rel(0.9)),
legend.position = "bottom",
legend.key = element_rect(fill = "transparent", colour = "transparent")) +
guides(colour = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1))
## Usar esse gráfico
datapred = as.data.frame(cbind(df_teste,Quantil,ey))
#datapred = datapred_model1
head(datapred)
#cr = 1 - sum(datapred$case_count > datapred$qs | datapred$case_count < datapred$qi)/(nrow(datapred))
#cr
#df$predict2 = datapred$qm
mean(abs(ey - df_teste$case_count))
library(Rcpp)
library(splines2)
library(LaplacesDemon)
library(Matrix)
library(parallel)
library(dplyr)
library(ggplot2)
##################
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
df = read.csv("datafinal.csv")
sourceCpp("func2_3.cpp")
library(Rcpp)
library(splines2)
library(LaplacesDemon)
library(Matrix)
library(parallel)
library(dplyr)
library(ggplot2)
##################
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
df = read.csv("datafinal.csv")
sourceCpp("funcs2_3.cpp")
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
source("Allmodels.R")
source("func_aux.R")
sourceCpp("arg_min.cpp")
sourceCpp("gradiente.cpp")
source("Allmodels.R")
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
df = read.csv("datafinal.csv")
sourceCpp("funcs2_3.cpp")
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
source("Allmodels.R")
source("func_aux.R")
sourceCpp("arg_min.cpp")
sourceCpp("gradiente.cpp")
############# Modelo 2 ################################################
### Transformacao em y
df_backup = df
df = df[1:floor(dim(df)[1]*0.9),]
#### Centrar e na centrar da a mesma coisa. Com ou sem intercepto tmb
df = as.data.frame(df)
A <- bernsteinPoly(df$case_count, degree = 20, intercept = FALSE,Boundary.knots = c(1,max(df$case_count)+10),data = df)
dim(A)
#umv = rep(1,dim(A)[1])
Ad = deriv(A)
#Xi0 = matrix(0,nrow(A), ncol(X))
q = ncol(A)
Sigma <- matrix(1,q,q)                             # Duplicate matrix
Sigma[upper.tri(Sigma)] <- 0          # Change lower triangular part
#Nao zerar
cmxy <- colMeans(A)
A <- sweep(A,2,cmxy)
A = A%*%Sigma
Ad = Ad%*%Sigma
index1 = c(rep(TRUE,q))
P <- diff(diag(q), differences = 1)
S <- crossprod(P)
P <- diff(diag(q), differences = 3)
S <- crossprod(P)
K1 = S
num_basis1 = q
Dp1 = diag(10^(-6),ncol(K1),ncol(K1))
dim(A)
dim(Ad)
K1 = K1 + Dp1
dim(K1)
############### Splines
head(df)
summary(df$dia)
Xyear <- bernsteinPoly(df$year, degree = 5, intercept = FALSE,Boundary.knots = c(1,7),data = df)
cmxYear <- colMeans(Xyear)
Xyear <- sweep(Xyear,2,cmxYear)
Xmes <- bernsteinPoly(df$mes, degree = 5, intercept = FALSE,Boundary.knots = c(1,12),data = df)
cmxMes <- colMeans(Xmes)
Xmes <- sweep(Xmes,2,cmxMes)
Xdia <- bernsteinPoly(df$dia, degree = 5, intercept = FALSE,Boundary.knots = c(1,7),data = df)
cmxDia <- colMeans(Xdia)
Xdia <- sweep(Xdia,2,cmxDia)
q = ncol(Xyear)
P <- diff(diag(q), differences = 3)
S <- crossprod(P)
K2 = S
num_basis1 = q
Dp1 = diag(10^(-6),ncol(K2),ncol(K2))
dim(A)
dim(Ad)
K2 = K2 + Dp1
#### fixed effects
Xperiod = model.matrix(~ 1 +Period2, data = df)
X = cbind(Xyear,Xmes,Xdia,Xperiod)
dim(X)
dim(K2)
#X = X[,-1]
index2 = rep(F,dim(X)[2])
############################################
Xrei = matrix(0,nrow(X),ncol(X))
A = cbind(A,X)
Ad = cbind(Ad,Xrei)
indext = c(index1,index2)
length(indext)
dim(A)
dim(Ad)
K3 = K2
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
source("Allmodels.R")
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
source("Allmodels.R")
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
model2 = function(A,Al,index,K1,K2,K3,X,n){
xin = rep(1,length(index))
xin2 = calc_x0(c(-1,-1,-1,-1),rep(1,length(index)),A,Al,index,K1,K2,K3,X)
n = dim(df)[1]
d = optim(par = c(0,0,0,0), fn = calc_lpost_cpp,xin = xin2, A = A,Al = Al,index = index,K1 = K1,K2 = K2,K3 = K3,X = X,n =n, method = "L-BFGS-B",
control=list(fnscale=-1,maxit = 5000,trace = TRUE),hessian = TRUE)
generate_uniform_grid <- function(dimension, num_points, min_values, max_values) {
# Verifica se os vetores de min e max têm o tamanho correto
if (length(min_values) != dimension || length(max_values) != dimension) {
stop("Os vetores min_values e max_values devem ter o mesmo comprimento que a dimensão.")
}
# Gera a grade usando expand.grid
ranges <- lapply(1:dimension, function(i) seq(from = min_values[i], to = max_values[i], length.out = num_points))
grid <- do.call(expand.grid, ranges)
# Calcula os pesos para cada célula da grade
cell_volume <- prod((max_values - min_values) / (num_points - 1))  # Volume de cada célula da grade
weights <- rep(cell_volume, nrow(grid))
return(list(points = grid, weights = weights))
}
min_values = d$par - 2*sqrt(diag(solve(-(d$hessian))))
max_values = d$par + 2*sqrt(diag(solve(-(d$hessian))))
result <- generate_uniform_grid(4, 4, min_values, max_values)
calc_lpost32 = function(sigma,xin) {
x0 = calc_x0(sigma,xin,A,Al,index,K1,K2,K3,X)
H  = calc_neg_hess_ff4(x0,sigma,A,Al,K1,K2,K3,X,index)
chol_h = chol(H)
calc_ljoint(A,x0, sigma, Al,K1,K2,K3,X,index) + (n/2)*log(2*pi)- sum(log(diag(chol_h)))
}
# Visualiza os pontos e os pesos
pontos2 <- as.matrix(result$points)
weights <- c(result$weights)
v.f.w = unlist(mclapply( as.data.frame(t(pontos2)), calc_lpost32,xin = xin2,mc.cores = 6 ))
unl = v.f.w - mean(v.f.w)
post_alpha =exp(unl)/sum(exp(unl)*weights)
means = (sapply(1:dim(pontos2)[1], function(i) calc_x0(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X)))
sigmas_beta = sapply(1:dim(pontos2)[1], function(i) vari = diag(chol2inv(chol(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1,K2 = K2,K3,index = index,X = X)))))
sigmas = pontos2
nsigmas = dim(sigmas)[1]
system.time({correções3 = mclapply(1:nsigmas, function(i) teste = optim(rep(0,length(index)),arg_min22, gr = gradiente_f,
H = solve(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1, K2 = K2, K3 = K3, index = index,X = X)),  A = A,
mu_ini = c(means[,i]),Al = Al, K_p = K(pontos2[i,],K1,K2,K3,X),index = index,
method = "BFGS")$par, mc.cores = 1)})
#correções3 = do.call(rbind,correções3)
#####################################
mu = means + correções3
mu_post = sapply(1:ncol(A), function(ii) weighted.mean(mu[ii,], w=post_alpha))
mu_post_old = sapply(1:ncol(A), function(ii) weighted.mean(means[ii,], w=post_alpha))
sigma_post =
sapply(1:ncol(A), function(ii)
weighted.mean((mu[ii,] - mu_post[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
sigma_post_old =
sapply(1:ncol(A), function(ii)
weighted.mean((means[ii,] - mu_post_old[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
beta_post = lapply(1:dim(A)[2],function(i) MH(i, mu_post = mu_post, mu = mu, sigmas_beta = sigmas_beta, post_alpha = post_alpha, weights = weights))
beta_post <- do.call(rbind, beta_post)
return(beta_post)
}
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
calc_lpost_cpp
model2 = function(A,Al,index,K1,K2,K3,X,n){
xin = rep(1,length(index))
xin2 = calc_x0(c(-1,-1,-1,-1),rep(1,length(index)),A,Al,index,K1,K2,K3,X)
n = dim(df)[1]
d = optim(par = c(0,0,0,0), fn = calc_lpost_cpp,xin = xin2, A = A,Al = Al,index = index,K1 = K1,K2 = K2,K3 = K3,X = X,n =n, method = "L-BFGS-B",
control=list(fnscale=-1,maxit = 5000,trace = TRUE),hessian = TRUE)
min_values = d$par - 2*sqrt(diag(solve(-(d$hessian))))
max_values = d$par + 2*sqrt(diag(solve(-(d$hessian))))
result <- generate_uniform_grid(4, 4, min_values, max_values)
# Visualiza os pontos e os pesos
pontos2 <- as.matrix(result$points)
weights <- c(result$weights)
v.f.w = sapply(1:(dim(pontos2)[1]), function(i) calc_lpost_cpp(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X,n))
unl = v.f.w - mean(v.f.w)
post_alpha =exp(unl)/sum(exp(unl)*weights)
sigmas_beta = sapply(1:dim(pontos2)[1], function(i) vari = diag(chol2inv(chol(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1,K2 = K2,K3,index = index,X = X)))))
sigmas = pontos2
nsigmas = dim(sigmas)[1]
system.time({correções3 = mclapply(1:nsigmas, function(i) teste = optim(rep(0,length(index)),arg_min22, gr = gradiente_f,
H = solve(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1, K2 = K2, K3 = K3, index = index,X = X)),  A = A,
mu_ini = c(means[,i]),Al = Al, K_p = K(pontos2[i,],K1,K2,K3,X),index = index,
method = "BFGS")$par, mc.cores = 6)})
#correções3 = do.call(rbind,correções3)
#####################################
mu = means + correções3
mu_post = sapply(1:ncol(A), function(ii) weighted.mean(mu[ii,], w=post_alpha))
mu_post_old = sapply(1:ncol(A), function(ii) weighted.mean(means[ii,], w=post_alpha))
sigma_post =
sapply(1:ncol(A), function(ii)
weighted.mean((mu[ii,] - mu_post[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
sigma_post_old =
sapply(1:ncol(A), function(ii)
weighted.mean((means[ii,] - mu_post_old[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
beta_post = lapply(1:dim(A)[2],function(i) MH(i, mu_post = mu_post, mu = mu, sigmas_beta = sigmas_beta, post_alpha = post_alpha, weights = weights))
beta_post <- do.call(rbind, beta_post)
return(beta_post)
}
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
calc_lpost_cpp
xin2 = calc_x0(c(1),rep(1,length(index)),A,Al,index,K1,X)
index = indext
Al = Ad
xin = rep(1,length(index))
xin2 = calc_x0(c(-1,-1,-1,-1),rep(1,length(index)),A,Al,index,K1,K2,K3,X)
n = dim(df)[1]
X = Xperiod
xin = rep(1,length(index))
xin2 = calc_x0(c(-1,-1,-1,-1),rep(1,length(index)),A,Al,index,K1,K2,K3,X)
n = dim(df)[1]
d = optim(par = c(0,0,0,0), fn = calc_lpost_cpp,xin = xin2, A = A,Al = Al,index = index,K1 = K1,K2 = K2,K3 = K3,X = X,n =n, method = "L-BFGS-B",
control=list(fnscale=-1,maxit = 5000,trace = TRUE),hessian = TRUE)
min_values = d$par - 2*sqrt(diag(solve(-(d$hessian))))
max_values = d$par + 2*sqrt(diag(solve(-(d$hessian))))
result <- generate_uniform_grid(4, 4, min_values, max_values)
# Visualiza os pontos e os pesos
pontos2 <- as.matrix(result$points)
weights <- c(result$weights)
v.f.w = sapply(1:(dim(pontos2)[1]), function(i) calc_lpost_cpp(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X,n))
unl = v.f.w - mean(v.f.w)
post_alpha =exp(unl)/sum(exp(unl)*weights)
sigmas_beta = sapply(1:dim(pontos2)[1], function(i) vari = diag(chol2inv(chol(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1,K2 = K2,K3,index = index,X = X)))))
sigmas = pontos2
model2 = function(A,Al,index,K1,K2,K3,X,n){
xin = rep(1,length(index))
xin2 = calc_x0(c(-1,-1,-1,-1),rep(1,length(index)),A,Al,index,K1,K2,K3,X)
n = dim(df)[1]
d = optim(par = c(0,0,0,0), fn = calc_lpost_cpp,xin = xin2, A = A,Al = Al,index = index,K1 = K1,K2 = K2,K3 = K3,X = X,n =n, method = "L-BFGS-B",
control=list(fnscale=-1,maxit = 5000,trace = TRUE),hessian = TRUE)
min_values = d$par - 2*sqrt(diag(solve(-(d$hessian))))
max_values = d$par + 2*sqrt(diag(solve(-(d$hessian))))
result <- generate_uniform_grid(4, 4, min_values, max_values)
# Visualiza os pontos e os pesos
pontos2 <- as.matrix(result$points)
weights <- c(result$weights)
v.f.w = sapply(1:(dim(pontos2)[1]), function(i) calc_lpost_cpp(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X,n))
unl = v.f.w - mean(v.f.w)
post_alpha =exp(unl)/sum(exp(unl)*weights)
means = (sapply(1:dim(pontos2)[1], function(i) calc_x0(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X)))
sigmas_beta = sapply(1:dim(pontos2)[1], function(i) vari = diag(chol2inv(chol(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1,K2 = K2,K3,index = index,X = X)))))
sigmas = pontos2
nsigmas = dim(sigmas)[1]
system.time({correções3 = mclapply(1:nsigmas, function(i) teste = optim(rep(0,length(index)),arg_min22, gr = gradiente_f,
H = solve(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1, K2 = K2, K3 = K3, index = index,X = X)),  A = A,
mu_ini = c(means[,i]),Al = Al, K_p = K(pontos2[i,],K1,K2,K3,X),index = index,
method = "BFGS")$par, mc.cores = 1)})
#correções3 = do.call(rbind,correções3)
#####################################
mu = means + correções3
mu_post = sapply(1:ncol(A), function(ii) weighted.mean(mu[ii,], w=post_alpha))
mu_post_old = sapply(1:ncol(A), function(ii) weighted.mean(means[ii,], w=post_alpha))
sigma_post =
sapply(1:ncol(A), function(ii)
weighted.mean((mu[ii,] - mu_post[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
sigma_post_old =
sapply(1:ncol(A), function(ii)
weighted.mean((means[ii,] - mu_post_old[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
beta_post = lapply(1:dim(A)[2],function(i) MH(i, mu_post = mu_post, mu = mu, sigmas_beta = sigmas_beta, post_alpha = post_alpha, weights = weights))
beta_post <- do.call(rbind, beta_post)
return(beta_post)
}
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
model2 = function(A,Al,index,K1,K2,K3,X,n){
xin = rep(1,length(index))
xin2 = calc_x0(c(-1,-1,-1,-1),rep(1,length(index)),A,Al,index,K1,K2,K3,X)
n = dim(df)[1]
d = optim(par = c(0,0,0,0), fn = calc_lpost_cpp,xin = xin2, A = A,Al = Al,index = index,K1 = K1,K2 = K2,K3 = K3,X = X,n =n, method = "L-BFGS-B",
control=list(fnscale=-1,maxit = 5000,trace = TRUE),hessian = TRUE)
min_values = d$par - 2*sqrt(diag(solve(-(d$hessian))))
max_values = d$par + 2*sqrt(diag(solve(-(d$hessian))))
result <- generate_uniform_grid(4, 4, min_values, max_values)
# Visualiza os pontos e os pesos
pontos2 <- as.matrix(result$points)
weights <- c(result$weights)
v.f.w = sapply(1:(dim(pontos2)[1]), function(i) calc_lpost_cpp(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X,n))
unl = v.f.w - mean(v.f.w)
post_alpha =exp(unl)/sum(exp(unl)*weights)
means = (sapply(1:dim(pontos2)[1], function(i) calc_x0(pontos2[i,], xin2,A,Al,index,K1,K2,K3,X)))
sigmas_beta = sapply(1:dim(pontos2)[1], function(i) vari = diag(chol2inv(chol(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1,K2 = K2,K3,index = index,X = X)))))
sigmas = pontos2
nsigmas = dim(sigmas)[1]
print("agora")
system.time({correções3 = mclapply(1:nsigmas, function(i) teste = optim(rep(0,length(index)),arg_min22, gr = gradiente_f,
H = solve(calc_neg_hess_ff4(means[,i],pontos2[i,],A = A, Al = Al, K1 = K1, K2 = K2, K3 = K3, index = index,X = X)),  A = A,
mu_ini = c(means[,i]),Al = Al, K_p = K(pontos2[i,],K1,K2,K3,X),index = index,
method = "BFGS")$par, mc.cores = 6)})
#correções3 = do.call(rbind,correções3)
#####################################
mu = means + correções3
mu_post = sapply(1:ncol(A), function(ii) weighted.mean(mu[ii,], w=post_alpha))
mu_post_old = sapply(1:ncol(A), function(ii) weighted.mean(means[ii,], w=post_alpha))
sigma_post =
sapply(1:ncol(A), function(ii)
weighted.mean((mu[ii,] - mu_post[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
sigma_post_old =
sapply(1:ncol(A), function(ii)
weighted.mean((means[ii,] - mu_post_old[ii])^2 + sigmas_beta[ii,], w=post_alpha)
) %>%
sqrt
beta_post = lapply(1:dim(A)[2],function(i) MH(i, mu_post = mu_post, mu = mu, sigmas_beta = sigmas_beta, post_alpha = post_alpha, weights = weights))
beta_post <- do.call(rbind, beta_post)
return(beta_post)
}
########## Fitting
system.time({m2 = model2(A,Ad,indext,K1,K2,K3,Xperiod,n)})
